
> [!info] Info
> 
[Prompt-engineering Roadmap](https://roadmap.sh/prompt-engineering)

-  LLMs and How They Work
-  What is a Prompt?
-  What is Prompt Engineering?

## LLMs and How They Work

简单来说，**大语言模型（Large Language Model，简称 LLM）**就像是一个读过人类历史上几乎所有公开文字的“超级学生”。它不仅能背书，还能通过理解文字间的统计规律，学会逻辑推理、编写代码甚至进行文学创作。

要深入理解它，我们可以将其拆解为：**它是如何“阅读”的**、**它是如何“思考”的**，以及**它是如何“进化”的**。

---

## 1. 它是如何“阅读”的：Token 与向量化

机器并不认识汉字或单词，它们只认识数字。所以第一步是**数据转化**。

- **分词 (Tokenization)：** 模型会将一段话切分成一个个小块，称为 **Token**。一个 Token 可能是一个词、一个字，甚至是一个后缀。
- **嵌入 (Embedding)：** 每个 Token 会被转化成一串长长的数字列表（向量）。在这个“数学空间”里，意思相近的词（如“猫”和“狗”）距离会非常近，而无关的词（如“猫”和“手机”）距离较远。

### 如何分词的
不同的模型使用的分词算法是不同的，目前大部分的模型大多都是基于 `BPE`和 `Unigram`两种算法。


### 
---

## 2. 核心心脏：Transformer 与自注意力机制

这是 LLM 能够理解语境的“黑科技”。在 Transformer 架构出现之前，AI 很难处理长句子，因为它们容易忘掉前面的内容。

**自注意力机制 (Self-Attention)** 解决了这个问题。当模型处理一个词时，它会同时“观察”句子中所有的其他词，并计算它们之间的关联权重。

> **例子：** “他把**苹果**给了小明，因为它很**熟**。”
> 
> 当模型处理“熟”这个词时，注意力机制会给“苹果”分配极高的权重，而给“小明”分配极低的权重。这样模型就精确知道了谁才是“熟”的主语。

---

## 3. 它如何生成回答：概率接龙

LLM 的运作本质上是一个极其复杂的**概率预测游戏**。当你给它一个提示词（Prompt）时，它在做的事情是：**预测下一个最合理的 Token 是什么？**

1. **输入：** “人工智能的未来是...”
    
2. **计算：** 模型根据已有的百亿级参数，计算所有可能的下一个词的概率：
    
    - “光明” (45%)
        
    - “不确定” (20%)
        
    - “挑战” (10%)
        
3. **输出：** 它选择“光明”。
    
4. **循环：** 现在的输入变成了“人工智能的未来是光明”，它再继续预测下一个字，直到遇到停止符号。
    

---

## 4. 训练的三部曲：从“书呆子”到“全才”

要把一个模型训练得像 Gemini 或 GPT 这么智能，通常需要三个阶段：

|**阶段**|**过程**|**比喻**|
|---|---|---|
|**预训练 (Pre-training)**|在数万亿的网页、书籍数据上进行无监督学习。|**疯狂读书：** 读完图书馆所有书，但不知道对错。|
|**指令微调 (SFT)**|人类编写高质量的问答对，告诉模型什么样才是好的回答。|**导师指导：** 老师批改作业，教它如何回答问题。|
|**人类反馈强化学习 (RLHF)**|模型生成多个答案，由人类进行打分排序，优化它的偏好。|**性格塑造：** 纠正它的价值观，让它更有礼貌、更安全。|

---

## 5. 为什么它看起来有智能？（涌现能力）

当模型的参数规模（神经元连接数）达到一定临界点时（通常是百亿级），它会展现出一些原本没有被专门训练过的能力，比如：

- **零样本推理：** 没见过的题也能举一反三。
    
- **多步逻辑：** 能够处理复杂的数学证明。
    
- **上下文学习：** 你在对话里教它一个规则，它立刻就能学会。
    

这种现象在科学上被称为**“涌现” (Emergence)**。

---

### 技术背后的数学公式

如果你对底层的数学感兴趣，Transformer 中最核心的注意力机制可以用这个公式表示：

$$Attention(Q, K, V) = softmax\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

其中 $Q, K, V$ 分别代表查询（Query）、键（Key）和值（Value），它们共同决定了模型在处理当前词时，应该分多少精力给上下文中的其他词。

**你想尝试用这些原理来优化你正在写的 Prompt（提示词），看看如何通过调整语境来改变模型的“概率预测”吗？**


## Sampling Parameters

## Output Control

## Repetition Penalties

## Structured Outputs

## Prompting Techniques

## Automatic Prompt Engineering
## AI Red Teaming

